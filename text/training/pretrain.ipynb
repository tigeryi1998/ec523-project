{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..data_util import *\n",
    "from ..textencoder import Encoder\n",
    "from ...data2vec import Data2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, path, epoch_num):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    path = os.path.join(path, f'ckpt{epoch_num}.pt')\n",
    "    checkpoint = {\n",
    "        'data2vec': model.state_dict(),\n",
    "        'encoder': model.encoder.encoder.state_dict()\n",
    "      }\n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up system config stuff\n",
    "device = 'cuda:0'\n",
    "num_epochs = 20\n",
    "ckpt_dir = './checkpoints/roberta-base'\n",
    "\n",
    "# Model, Criterion, Optimizer\n",
    "encoder = Encoder('roberta-base')\n",
    "model = Data2Vec(encoder=encoder, modality='text', embed_dim=768, ema_decay=0.9998, ema_end_decay=0.9999, ema_anneal_end_step=300000, device=device)\n",
    "optimizer = optim.AdamW(model.parameters(), 2e-3)\n",
    "criterion = nn.SmoothL1Loss(reduction='none', beta=2)\n",
    "criterion.to(device)\n",
    "\n",
    "# Datasets & Data Loaders\n",
    "train_dataset = WikiDataset(device, './wikitext-103-v1')\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Trackers\n",
    "loss_tracker = AverageMeter('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model, then save\n",
    "model.train()\n",
    "num_epochs = 20\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    with tqdm(train_loader, unit=\"batch\", desc=f'Epoch: {epoch} ',\n",
    "          bar_format='{desc:<16}{percentage:3.0f}%|{bar:70}{r_bar}', ascii=\" #\") as iterator:\n",
    "        for batch in iterator:\n",
    "\n",
    "            # get data, move to device\n",
    "            src, trg, mask = batch\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            # pass through model\n",
    "            x, y = model(src, trg, mask)\n",
    "            loss = criterion(x.float(), y.float()).sum(dim=-1).sum().div(x.size(0))\n",
    "            # update parameters\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # get loss, update teacher model, keep track of loss\n",
    "            loss_tracker.update(loss.item())\n",
    "            model.ema_step()\n",
    "            iterator.set_postfix(loss=loss_tracker.avg)\n",
    "            \n",
    "    if epoch%5==0:\n",
    "        save_checkpoint(model, './checkpoints/', epoch)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
